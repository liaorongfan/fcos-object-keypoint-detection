{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python知识点：\n",
    "## os.path.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm Vamei. I'm 99 year old\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 字符串模板\n",
    "print(\"I'm %s. I'm %d year old\" % ('Vamei', 99))  # %s 字符 格式符  %d 整数格式符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home\\Annotations\\%s.xml\n",
      "home\\Annotations\\001.xml\n"
     ]
    }
   ],
   "source": [
    "base = os.path.join('home', \"Annotations\", \"%s.xml\"); print(base)\n",
    "print(base % \"001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "home\\ImageSets\\Main\\trainval.txt\n"
     ]
    }
   ],
   "source": [
    "self_imgsetpath = os.path.join(\"home\", \"ImageSets\", \"Main\", \"%s.txt\")\n",
    "self_imgset = 'trainval'\n",
    "print(self_imgsetpath % self_imgset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tqdm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for item in tqdm(range(100)):\n",
    "    # do something\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a\n",
      "1 b\n",
      "2 c\n"
     ]
    }
   ],
   "source": [
    "lt=['a','b','c']\n",
    "for i, item in enumerate(lt):\n",
    "    print(i,item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 1511.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 a\n",
      "1 b\n",
      "2 c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lt=['a','b','c']\n",
    "for i,item in enumerate(tqdm(lt)):\n",
    "    print(i,item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assert()\n",
    "不满足expression条件的话报错\n",
    "```python\n",
    "assert expression [, arguments]\n",
    "```\n",
    "\n",
    "等价于：\n",
    "\n",
    "```python\n",
    "if not expression:\n",
    "    raise AssertionError(arguments)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything is good\n"
     ]
    }
   ],
   "source": [
    "assert 1==1\n",
    "print('everything is good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "not good",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ef72dc0d4f87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'not good'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'everything is good'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: not good"
     ]
    }
   ],
   "source": [
    "assert 1==2, 'not good'\n",
    "print('everything is good')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [zip()](https://www.runoob.com/python/python-func-zip.html)\n",
    "zip() 函数用于将`可迭代的对象`作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的`可迭代对象`。\n",
    "\n",
    "利用` * 号操作符`，可以将元组`解压`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x20ead6172c8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "zipped = zip(a,b)     # 打包为元组的列表\n",
    "zipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (3, 6)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (4, 5, 6)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*zipped))       # 与 zip 相反，*zipped 可理解为解压，返回二维矩阵式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 3), (2, 4)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [(1,2), (3,4)]\n",
    "list(zip(*c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [map()](https://www.runoob.com/python/python-func-map.html)\n",
    "\n",
    "map() 函数语法：\n",
    "```python\n",
    "map(function, iterable, ...)\n",
    "```\n",
    "map() 会根据提供的函数对指定序列做映射,返回值为`可迭代对象`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square(x) :            # 计算平方数\n",
    "     return x ** 2\n",
    "\n",
    "list(map(square, [1,2,3,4,5]))   # 计算列表各个元素的平方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x ** 2, [1, 2, 3, 4, 5]))  # 使用 lambda 匿名函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 7, 11, 15, 19]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 提供了两个列表，对相同位置的列表数据进行相加\n",
    "list(map(lambda x, y: x + y, [1, 3, 5, 7, 9], [2, 4, 6, 8, 10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## array[...,n]\n",
    "只看最后一个维度，按列选取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[48, 40,  3]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[[10, 12, 48, 60],\n",
    "               [10, 20, 40, 50],\n",
    "               [1,  2,  3,  4]]])\n",
    "print(y.shape)\n",
    "y[..., 2]  # 取第一列  所有gt框的xmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.arange(24).reshape(2,3,4)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  4,  8],\n",
       "       [12, 16, 20]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[..., 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch知识点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TENSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.tensor.type()\n",
    "**查看张量类型：**tensor.dtype\n",
    "\n",
    "**张量类型转换：**tensor.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1779, 0.6435, 0.2026, 0.8128],\n",
      "        [0.8908, 0.9878, 0.8509, 0.6694]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand((2,4))\n",
    "print(tensor)\n",
    "print(tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1779, 0.6435, 0.2026, 0.8128],\n",
      "        [0.8908, 0.9878, 0.8509, 0.6694]], dtype=torch.float64)\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "tensor = tensor.type(torch.float64)\n",
    "print(tensor)\n",
    "print(tensor.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.from_numpy()\n",
    "将numpy格式数据转换成torch.tensor\n",
    ">torch.numpy() ：将tensor转换成numpy数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy的array与torch的tensor的转换\n",
    "np_data = np.arange(6).reshape((2, 3))\n",
    "np_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [3, 4, 5]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_data = torch.from_numpy(np_data)\n",
    "torch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2array = torch_data.numpy() \n",
    "tensor2array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.permute()\n",
    "改变张量轴的顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "torch.Size([5, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 5)\n",
    "print(x.size())\n",
    "print(x.permute(2, 0, 1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.reshape()\n",
    "调整张量形状"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5623,  1.5738, -0.0117, -0.4112,  0.6413],\n",
       "         [ 0.7338, -0.8092, -0.7477, -0.0963,  0.7245]],\n",
       "\n",
       "        [[-0.2340, -1.5358,  0.4822,  0.7625,  0.6357],\n",
       "         [ 0.4128, -0.5038, -0.4117, -0.8000,  0.0706]],\n",
       "\n",
       "        [[-0.8159,  0.6847,  0.1068, -1.2137,  0.3526],\n",
       "         [-0.9043,  0.3554,  0.6052, -0.8652,  1.0381]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 5)\n",
    "x.reshape(3,2,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape([-1])  # 将x拉成一列\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [torch.arange()](https://pytorch.org/docs/stable/generated/torch.arange.html)\n",
    "生成张量序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6., 8.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 5 * 2, 2, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [torch.stack()](https://blog.csdn.net/xinjieyuan/article/details/105205326)\n",
    ">torch.stack(tensors, dim=0, out=None) → Tensor\n",
    "\n",
    "Concatenates sequence of tensors along a new dimension.  All tensors need to be of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设是时间步T1\n",
    "T1 = torch.tensor([[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]])\n",
    "# 假设是时间步T2\n",
    "T2 = torch.tensor([[10, 20, 30],\n",
    "                [40, 50, 60],\n",
    "                [70, 80, 90]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9]],\n",
       "\n",
       "        [[10, 20, 30],\n",
       "         [40, 50, 60],\n",
       "         [70, 80, 90]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((T1,T2),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack((T1,T2),dim=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1, 10],\n",
       "         [ 2, 20],\n",
       "         [ 3, 30]],\n",
       "\n",
       "        [[ 4, 40],\n",
       "         [ 5, 50],\n",
       "         [ 6, 60]],\n",
       "\n",
       "        [[ 7, 70],\n",
       "         [ 8, 80],\n",
       "         [ 9, 90]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((T1,T2),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack((T1,T2),dim=-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [torch.cat()](https://pytorch.org/docs/stable/generated/torch.cat.html)\n",
    ">torch.cat(tensors, dim=0, out=None) → Tensor\n",
    "\n",
    "Concatenates the given sequence of seq tensors in the given dimension. All tensors must either have the same shape (except in the concatenating dimension) or be empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3, 10, 20, 30],\n",
       "        [ 4,  5,  6, 40, 50, 60],\n",
       "        [ 7,  8,  9, 70, 80, 90]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((T1,T2),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9],\n",
       "        [10, 20, 30],\n",
       "        [40, 50, 60],\n",
       "        [70, 80, 90]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((T1,T2),dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.meshgrid()\n",
    "生成网格，可以用于生成坐标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3, 4])\n",
    "print(a)\n",
    "b = torch.tensor([4, 5, 6])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [2, 2, 2],\n",
      "        [3, 3, 3],\n",
      "        [4, 4, 4]])\n",
      "tensor([[4, 5, 6],\n",
      "        [4, 5, 6],\n",
      "        [4, 5, 6],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "x, y = torch.meshgrid(a, b)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2508354d748>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coords_fmap2orig(feature, stride=16):  # 特征图上的grid对应于原图的位置\n",
    "    h, w = feature.shape[1:3]  \n",
    "    # h, w = 8, 8 # 为演示方便，我们使用尺寸为（4，4）的特征图\n",
    "    shifts_x = torch.arange(0, w * stride, stride, dtype=torch.float32)\n",
    "    shifts_y = torch.arange(0, h * stride, stride, dtype=torch.float32)\n",
    "    shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)\n",
    "    shift_x = torch.reshape(shift_x, [-1])\n",
    "    shift_y = torch.reshape(shift_y, [-1])\n",
    "    coords = torch.stack([shift_x, shift_y], -1) + (stride // 2)  # 中心点偏置\n",
    "    # 可视化一下，看看\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.scatter(coords[:,0], coords[:,1])\n",
    "    # plt.savefig('grid.png')\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.,  8.],\n",
       "        [24.,  8.],\n",
       "        [40.,  8.],\n",
       "        [56.,  8.],\n",
       "        [ 8., 24.],\n",
       "        [24., 24.],\n",
       "        [40., 24.],\n",
       "        [56., 24.],\n",
       "        [ 8., 40.],\n",
       "        [24., 40.],\n",
       "        [40., 40.],\n",
       "        [56., 40.],\n",
       "        [ 8., 56.],\n",
       "        [24., 56.],\n",
       "        [40., 56.],\n",
       "        [56., 56.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature = torch.rand((2,4,4))\n",
    "coords = coords_fmap2orig(feature)\n",
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [None] for Dimension\n",
    "用于增加张量维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.int32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(10,dtype=torch.int32)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0],\n",
       "         [1],\n",
       "         [2],\n",
       "         [3],\n",
       "         [4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [7],\n",
       "         [8],\n",
       "         [9]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x[None, :, None].shape)\n",
    "x[None, :, None]  # None 用于增加维度 相当于把数据都放到行维度上 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "torch.int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[10, 20]], dtype=torch.int32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.from_numpy(\n",
    "    np.array([[[10, 12, 48, 60],\n",
    "               [20, 20, 40, 50]]])\n",
    "    )\n",
    "\n",
    "print(y[..., 0].shape)\n",
    "print(y.dtype)\n",
    "y[..., 0]  # 取第一列  所有gt框的xmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[10, 20]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y[..., 0][:, None, :].shape)\n",
    "y[..., 0][:, None, :]  #  增加维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-10, -20],\n",
       "         [ -9, -19],\n",
       "         [ -8, -18],\n",
       "         [ -7, -17],\n",
       "         [ -6, -16],\n",
       "         [ -5, -15],\n",
       "         [ -4, -14],\n",
       "         [ -3, -13],\n",
       "         [ -2, -12],\n",
       "         [ -1, -11]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1,10,1]-[1,1,2]-->[1, 10, 2]\n",
    "off = x[None, :, None] - y[..., 0][:, None, :]   # None 增加维度用的\n",
    "off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [torch.sum（）](https://blog.csdn.net/weixin_45281949/article/details/103282148?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.channel_param)\n",
    "\n",
    "张量求和函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[1,2,3,1,2],\n",
    "                   [4,5,6,3,4]],\n",
    "                  \n",
    "                  [[7,8,9,2,3],\n",
    "                   [1,1,2,1,2]],\n",
    "                  \n",
    "                  [[7,8,9,2,3],\n",
    "                   [1,1,2,1,2]]])\n",
    "print(a.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/3-axis_front.png\" width=\"300\" height=\"400\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[15, 18, 21,  5,  8],\n",
      "        [ 6,  7, 10,  5,  8]]) torch.Size([2, 5])\n"
     ]
    }
   ],
   "source": [
    "b = torch.sum(a,dim=0)\n",
    "print(b, b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  7,  9,  4,  6],\n",
      "        [ 8,  9, 11,  3,  5],\n",
      "        [ 8,  9, 11,  3,  5]]) torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "c = torch.sum(a,dim=1)\n",
    "print(c,c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9, 22],\n",
      "        [29,  7],\n",
      "        [29,  7]]) torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "b = torch.sum(a,dim=2)\n",
    "print(b,b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([31, 36, 36]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "b = torch.sum(a,dim=(1,2))\n",
    "print(b,b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([31, 36, 36]) torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "b = torch.sum(a,dim=(2,1))\n",
    "print(b,b.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [torch.clamp()](https://blog.csdn.net/u013230189/article/details/82627375)\n",
    "截断函数，超出范围的值用指定值代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8],\n",
      "        [0],\n",
      "        [4],\n",
      "        [9],\n",
      "        [0],\n",
      "        [3],\n",
      "        [2],\n",
      "        [2],\n",
      "        [8],\n",
      "        [2]])\n",
      "tensor([[6],\n",
      "        [3],\n",
      "        [4],\n",
      "        [6],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [3],\n",
      "        [6],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randint(low=0,high=10,size=(10,1))\n",
    "print(a)\n",
    "a=torch.clamp(a,3,6)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.min()/max()\n",
    "按维度选取张量中的最值，返回值和索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(24).reshape(2,3,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.min(\n",
       "values=tensor([[ 0,  4,  8],\n",
       "        [12, 16, 20]]),\n",
       "indices=tensor([[0, 0, 0],\n",
       "        [0, 0, 0]]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x, dim=-1)  # dim=-1 在行上看各列的大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8756, 0.8750, 0.2613, 0.6496],\n",
       "        [0.9187, 0.3337, 0.7023, 0.7116],\n",
       "        [0.8018, 0.7570, 0.6279, 0.9496]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand((3,4))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.8756, 0.9187, 0.9496]),\n",
       "indices=tensor([0, 0, 3]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(y, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 0, 1],\n",
       "        [1, 0, 1, 1],\n",
       "        [1, 1, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.scatter_()\n",
    ">output = torch.Tensor.scatter_(dim, index, src)\n",
    "\n",
    "[.scatter_()](https://blog.csdn.net/weixin_45798469/article/details/108311046)本身的用法有些繁琐，但是这里可以用来生成[独热编码](https://blog.csdn.net/u010630669/article/details/105425572)\n",
    "\n",
    "\n",
    "[Reference](https://medium.com/@yang6367/understand-torch-scatter-b0fd6275331c)(有空可以看看)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = torch.tensor([1,2,1,2,0])  # [1,2,1,2,0] 5个元素对应5行，0，1，2 对应3列\n",
    "x = torch.zeros(5,3).scatter_(-1, index.unsqueeze(1), 1) \n",
    "x = x.type(torch.uint8)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0],\n",
       "         [ 1],\n",
       "         [ 2]],\n",
       "\n",
       "        [[ 3],\n",
       "         [ 4],\n",
       "         [ 5]],\n",
       "\n",
       "        [[ 6],\n",
       "         [ 7],\n",
       "         [ 8]],\n",
       "\n",
       "        [[ 9],\n",
       "         [10],\n",
       "         [11]],\n",
       "\n",
       "        [[12],\n",
       "         [13],\n",
       "         [14]]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.arange(15).reshape(5,3,1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1],\n",
       "        [ 5],\n",
       "        [ 7],\n",
       "        [11],\n",
       "        [12]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.broadcast_tensors\n",
    ">torch.broadcast_tensors(*tensors) → List of Tensors\n",
    "\n",
    "Broadcasts the given tensors according to Broadcasting semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2]])\n",
      "tensor([[0],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(3).view(1, 3)\n",
    "y = torch.arange(2).view(2, 1)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) \n",
      " tensor([[0, 1, 2],\n",
      "        [0, 1, 2]])\n",
      "torch.Size([2, 3]) \n",
      " tensor([[0, 0, 0],\n",
      "        [1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "a, b = torch.broadcast_tensors(x, y)\n",
    "\n",
    "print(a.shape,'\\n',a)\n",
    "print(b.shape,'\\n',b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [nn.parameter](https://www.jianshu.com/p/d8b77cc02410)\n",
    "可以把这个函数理解为类型转换函数，将一个不可训练的数据类型Tensor转换成可以训练的数据类型parameter，并将这个parameter绑定到这个module里面\n",
    "\n",
    "(net.parameter()中就有这个绑定的parameter，所以在参数优化的时候可以进行优化)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class ScaleExp(nn.Module):\n",
    "    def __init__(self, init_value=1.0):\n",
    "        super(ScaleExp, self).__init__()\n",
    "        self.scale = nn.Parameter(torch.tensor([init_value], dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.exp(x * self.scale)  # 乘一个 可以训练的 缩放因子 scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_backend': <torch.nn.backends.thnn.THNNFunctionBackend at 0x20dca0a9bc8>,\n",
       " '_parameters': OrderedDict([('scale',\n",
       "               Parameter containing:\n",
       "               tensor([2.], requires_grad=True))]),\n",
       " '_buffers': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict(),\n",
       " 'training': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_model = ScaleExp(2)\n",
    "scale_model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('scale',\n",
       "              Parameter containing:\n",
       "              tensor([2.], requires_grad=True))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale_model._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones((2,3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.3891, 7.3891, 7.3891],\n",
       "        [7.3891, 7.3891, 7.3891]], grad_fn=<ExpBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = scale_model(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.38905609893065"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(2)  # e**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [nn.ModuleList()](https://zhuanlan.zhihu.com/p/64990232)\n",
    "它是一个储存不同 module，并自动将每个 module 的 parameters 添加到网络之中的容器。但，我们需要注意的是，nn.ModuleList 并没有定义一个网络，它只是将不同的模块储存在一起，这些模块在网络之中的先后顺序`由forward函数定义`，与它们在ModuleList中的顺序没有关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): ScaleExp()\n",
       "  (1): ScaleExp()\n",
       "  (2): ScaleExp()\n",
       "  (3): ScaleExp()\n",
       "  (4): ScaleExp()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_scale_exp = nn.ModuleList([ScaleExp(1.0) for _ in range(5)])\n",
    "self_scale_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [nn.GroupNorm()](https://pytorch.org/docs/stable/generated/torch.nn.GroupNorm.html)\n",
    ">torch.nn.GroupNorm(num_groups: int, num_channels: int, eps: float = 1e-05, affine: bool = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 10, 10])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(2, 6, 10, 10)\n",
    "# Separate 6 channels into 3 groups\n",
    "m = nn.GroupNorm(3, 6)\n",
    "# Separate 6 channels into 6 groups (equivalent with InstanceNorm)\n",
    "# m = nn.GroupNorm(6, 6)\n",
    "# Put all 6 channels into a single group (equivalent with LayerNorm)\n",
    "# m = nn.GroupNorm(1, 6)\n",
    "# Activating the module\n",
    "output = m(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [nn.init.constant_()](https://pytorch.org/docs/stable/nn.init.html)\n",
    ">torch.nn.init.constant_(tensor, val)\n",
    "\n",
    "Fills the input Tensor with the value \\text{val}val ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000, 0.3000, 0.3000, 0.3000, 0.3000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.3000, 0.3000],\n",
       "        [0.3000, 0.3000, 0.3000, 0.3000, 0.3000]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(3, 5)\n",
    "nn.init.constant_(w, 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.init.normal_()\n",
    ">torch.nn.init.normal_(tensor, mean=0.0, std=1.0)\n",
    "\n",
    "Fills the input Tensor with values drawn from the normal distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6992, 0.4720, 0.7449, 0.9687, 0.2162],\n",
       "        [0.6403, 0.9436, 0.7179, 0.5932, 0.3606],\n",
       "        [0.9113, 0.4005, 0.8603, 0.5484, 0.7761]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.empty(3, 5)\n",
    "nn.init.uniform_(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.functional.pad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.pad(input, pad, mode,value ) \n",
    "    \"\"\"\n",
    "    input：四维或者五维的tensor Variabe\n",
    "    pad：不同Tensor的填充方式\n",
    "        1.四维Tensor：传入四元素tuple(pad_l, pad_r, pad_t, pad_b)，\n",
    "        指的是（左填充，右填充，上填充，下填充），其数值代表填充次数\n",
    "        2.六维Tensor：传入六元素tuple(pleft, pright, ptop, pbottom, pfront, pback)，\n",
    "        指的是（左填充，右填充，上填充，下填充，前填充，后填充），其数值代表填充次数\n",
    "    mode： ’constant‘, ‘reflect’ or ‘replicate’三种模式，指的是常量，反射，复制三种模式\n",
    "    value：填充的数值，在\"contant\"模式下默认填充0，mode=\"reflect\" or \"replicate\"时没有默认value参数\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_values:  tensor([[[[-0.4688, -0.1474],\n",
      "          [-0.6680, -0.3156],\n",
      "          [-0.7283, -1.6244]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2516,  2.4004],\n",
      "          [ 0.3972, -2.2466],\n",
      "          [-0.7992,  0.5078]]]]) \n",
      "\n",
      "original_values的shape:  torch.Size([2, 1, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "original_values = torch.randn([2,1, 3, 2])\n",
    "print(\"original_values: \",original_values,\"\\n\")\n",
    "print(\"original_values的shape: \",original_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding_values:  tensor([[[[ 0.0000, -0.4688, -0.1474],\n",
      "          [ 0.0000, -0.6680, -0.3156],\n",
      "          [ 0.0000, -0.7283, -1.6244]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0000,  0.2516,  2.4004],\n",
      "          [ 0.0000,  0.3972, -2.2466],\n",
      "          [ 0.0000, -0.7992,  0.5078]]]]) \n",
      "\n",
      "padding_values的shape:  torch.Size([2, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "padding_values = F.pad(original_values, pad=(1,0,0,0), mode=\"constant\",value=0)  \n",
    "print(\"padding_values: \",padding_values,\"\\n\")\n",
    "print(\"padding_values的shape: \",padding_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding_values:  tensor([[[[-0.4688, -0.1474],\n",
      "          [-0.6680, -0.3156],\n",
      "          [-0.7283, -1.6244],\n",
      "          [-1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2516,  2.4004],\n",
      "          [ 0.3972, -2.2466],\n",
      "          [-0.7992,  0.5078],\n",
      "          [-1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000],\n",
      "          [-1.0000, -1.0000]]]]) \n",
      "\n",
      "padding_values的shape:  torch.Size([2, 1, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "padding_values = F.pad(original_values, pad=(0,0,0,3), mode=\"constant\",value=-1)  \n",
    "print(\"padding_values: \",padding_values,\"\\n\")\n",
    "print(\"padding_values的shape: \",padding_values.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [F.interpolate()](https://pytorch.org/docs/stable/nn.functional.html)\n",
    ">torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None)\n",
    "\n",
    "Down/up samples the input to either the given size or the given scale_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 8, 10])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = torch.rand((1,2,4,5))\n",
    "src_interp = F.interpolate(src, size=(8, 10),mode='nearest')\n",
    "src_interp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "torch1.1",
   "language": "python",
   "name": "torch1.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "242.62px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
