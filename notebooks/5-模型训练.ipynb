{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "os.chdir('../')  # 更改notebook的工作路径到上一级目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.VOC_dataset import VOCDataset\n",
    "from dataset.augment import Transforms\n",
    "import torch.nn as nn\n",
    "from model.backbone.resnet import resnet50\n",
    "from model.fcos import FCOS\n",
    "from model.loss import GenTargets, LOSS, coords_fmap2orig\n",
    "from model.fpn_neck import FPN\n",
    "from model.config import DefaultConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--epochs\", type=int, default=30, help=\"number of epochs\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=1, help=\"size of each image batch\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=0, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--n_gpu\", type=str, default='0,1', help=\"number of cpu threads to use during batch generation\")\n",
    "opt = parser.parse_args([])  # notebook 中运行的时候要加 parser.parse_args() 的参数要加[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU环境设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = opt.n_gpu\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "np.random.seed(0)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO=====>voc dataset init finished  ! !\n",
      "total_images : 5011\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = opt.batch_size\n",
    "\n",
    "transform = Transforms()\n",
    "train_dataset = VOCDataset(root_dir='../datasets/VOCdevkit/VOC2007', resize_size=[800, 1333],\n",
    "                           split='trainval', use_difficult=False, is_train=True, augment=transform)\n",
    "\n",
    "# WARMPUP_STEPS_RATIO = 0.12\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                                           collate_fn=train_dataset.collate_fn,\n",
    "                                           num_workers=opt.n_cpu, worker_init_fn=np.random.seed(0))\n",
    "\n",
    "print(\"total_images : {}\".format(len(train_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCOSDetector(nn.Module):\n",
    "    def __init__(self, config=None):\n",
    "        super().__init__()\n",
    "        if config is None:\n",
    "            config = DefaultConfig\n",
    "\n",
    "        self.fcos_body = FCOS(config=config)\n",
    "        self.target_layer = GenTargets(strides=config.strides, limit_range=config.limit_range)\n",
    "        self.loss_layer = LOSS()\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        FCOS网络\n",
    "        :param inputs:\n",
    "                [training] list  batch_images,batch_boxes,batch_classes\n",
    "        :return:\n",
    "                [training] losses\n",
    "        \"\"\"\n",
    "        batch_imgs, batch_boxes, batch_classes = inputs\n",
    "        # 模型输出\n",
    "        out = self.fcos_body(batch_imgs)\n",
    "        # 编码标签信息\n",
    "        targets = self.target_layer([out, batch_boxes, batch_classes])\n",
    "        # 计算标签和预测信息间的损失\n",
    "        losses = self.loss_layer([out, targets])\n",
    "        return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO===>success frozen BN\n",
      "INFO===>success frozen backbone stage1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FCOSDetector(\n",
       "  (fcos_body): FCOS(\n",
       "    (backbone): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
       "    )\n",
       "    (fpn): FPN(\n",
       "      (prj_5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (prj_4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (prj_3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv_5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv_4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv_out6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv_out7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (head): ClsCntRegHead(\n",
       "      (cls_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace)\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (8): ReLU(inplace)\n",
       "        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (10): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (11): ReLU(inplace)\n",
       "      )\n",
       "      (reg_conv): Sequential(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (2): ReLU(inplace)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (5): ReLU(inplace)\n",
       "        (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (8): ReLU(inplace)\n",
       "        (9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (10): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (11): ReLU(inplace)\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cnt_logits): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (reg_pred): Conv2d(256, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (scale_exp): ModuleList(\n",
       "        (0): ScaleExp()\n",
       "        (1): ScaleExp()\n",
       "        (2): ScaleExp()\n",
       "        (3): ScaleExp()\n",
       "        (4): ScaleExp()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (target_layer): GenTargets()\n",
       "  (loss_layer): LOSS()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FCOSDetector().cuda()\n",
    "# model = torch.nn.DataParallel(model)  # 多gpu时使用\n",
    "model.train()  # 设置为训练模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化器设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=2e-3, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     9
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_steps:1 epoch:1 steps:1/5011 cls_loss:1.1261 cnt_loss:0.6763 reg_loss:1.0000 cost_time:8497ms lr=3.9920e-06 total_loss:2.8024\n",
      "global_steps:2 epoch:1 steps:2/5011 cls_loss:1.1903 cnt_loss:0.6798 reg_loss:1.0000 cost_time:474ms lr=7.9840e-06 total_loss:2.8701\n",
      "global_steps:3 epoch:1 steps:3/5011 cls_loss:1.1981 cnt_loss:0.6578 reg_loss:1.0000 cost_time:404ms lr=1.1976e-05 total_loss:2.8559\n",
      "global_steps:4 epoch:1 steps:4/5011 cls_loss:1.2240 cnt_loss:0.6626 reg_loss:1.0000 cost_time:396ms lr=1.5968e-05 total_loss:2.8866\n",
      "global_steps:5 epoch:1 steps:5/5011 cls_loss:1.0087 cnt_loss:0.6284 reg_loss:0.9999 cost_time:410ms lr=1.9960e-05 total_loss:2.6370\n",
      "global_steps:6 epoch:1 steps:6/5011 cls_loss:1.1452 cnt_loss:0.6744 reg_loss:0.9999 cost_time:390ms lr=2.3952e-05 total_loss:2.8196\n",
      "global_steps:7 epoch:1 steps:7/5011 cls_loss:1.2322 cnt_loss:0.6345 reg_loss:1.0000 cost_time:528ms lr=2.7944e-05 total_loss:2.8667\n",
      "global_steps:8 epoch:1 steps:8/5011 cls_loss:1.1378 cnt_loss:0.6787 reg_loss:1.0000 cost_time:390ms lr=3.1936e-05 total_loss:2.8164\n",
      "global_steps:9 epoch:1 steps:9/5011 cls_loss:1.3520 cnt_loss:0.5775 reg_loss:0.9999 cost_time:436ms lr=3.5928e-05 total_loss:2.9294\n",
      "global_steps:10 epoch:1 steps:10/5011 cls_loss:0.9714 cnt_loss:0.6703 reg_loss:1.0000 cost_time:381ms lr=3.9920e-05 total_loss:2.6417\n",
      "global_steps:11 epoch:1 steps:11/5011 cls_loss:1.1897 cnt_loss:0.6246 reg_loss:1.0000 cost_time:342ms lr=4.3912e-05 total_loss:2.8142\n",
      "global_steps:12 epoch:1 steps:12/5011 cls_loss:1.0960 cnt_loss:0.6000 reg_loss:1.0000 cost_time:376ms lr=4.7904e-05 total_loss:2.6960\n",
      "global_steps:13 epoch:1 steps:13/5011 cls_loss:1.3383 cnt_loss:0.6642 reg_loss:1.0000 cost_time:472ms lr=5.1896e-05 total_loss:3.0025\n",
      "global_steps:14 epoch:1 steps:14/5011 cls_loss:1.1452 cnt_loss:0.6536 reg_loss:1.0000 cost_time:394ms lr=5.5888e-05 total_loss:2.7988\n",
      "global_steps:15 epoch:1 steps:15/5011 cls_loss:1.0130 cnt_loss:0.6054 reg_loss:0.9995 cost_time:402ms lr=5.9880e-05 total_loss:2.6179\n",
      "global_steps:16 epoch:1 steps:16/5011 cls_loss:1.1269 cnt_loss:0.6062 reg_loss:1.0000 cost_time:390ms lr=6.3872e-05 total_loss:2.7331\n",
      "global_steps:17 epoch:1 steps:17/5011 cls_loss:1.0594 cnt_loss:0.6341 reg_loss:1.0000 cost_time:392ms lr=6.7864e-05 total_loss:2.6935\n",
      "global_steps:18 epoch:1 steps:18/5011 cls_loss:1.1012 cnt_loss:0.6034 reg_loss:1.0000 cost_time:425ms lr=7.1856e-05 total_loss:2.7045\n",
      "global_steps:19 epoch:1 steps:19/5011 cls_loss:1.1334 cnt_loss:0.6778 reg_loss:0.9997 cost_time:428ms lr=7.5848e-05 total_loss:2.8109\n",
      "global_steps:20 epoch:1 steps:20/5011 cls_loss:1.2210 cnt_loss:0.6281 reg_loss:1.0000 cost_time:350ms lr=7.9840e-05 total_loss:2.8490\n",
      "global_steps:21 epoch:1 steps:21/5011 cls_loss:1.0061 cnt_loss:0.6366 reg_loss:1.0000 cost_time:429ms lr=8.3832e-05 total_loss:2.6427\n",
      "global_steps:22 epoch:1 steps:22/5011 cls_loss:1.1077 cnt_loss:0.6990 reg_loss:1.0000 cost_time:335ms lr=8.7824e-05 total_loss:2.8066\n",
      "global_steps:23 epoch:1 steps:23/5011 cls_loss:0.9289 cnt_loss:0.6567 reg_loss:0.9998 cost_time:391ms lr=9.1816e-05 total_loss:2.5854\n",
      "global_steps:24 epoch:1 steps:24/5011 cls_loss:1.0088 cnt_loss:0.6811 reg_loss:0.9999 cost_time:375ms lr=9.5808e-05 total_loss:2.6898\n",
      "global_steps:25 epoch:1 steps:25/5011 cls_loss:1.0446 cnt_loss:0.6467 reg_loss:1.0000 cost_time:412ms lr=9.9800e-05 total_loss:2.6912\n",
      "global_steps:26 epoch:1 steps:26/5011 cls_loss:1.2723 cnt_loss:0.6251 reg_loss:1.0000 cost_time:471ms lr=1.0379e-04 total_loss:2.8974\n",
      "global_steps:27 epoch:1 steps:27/5011 cls_loss:1.0728 cnt_loss:0.6030 reg_loss:1.0000 cost_time:399ms lr=1.0778e-04 total_loss:2.6758\n",
      "global_steps:28 epoch:1 steps:28/5011 cls_loss:0.8135 cnt_loss:0.6586 reg_loss:0.9993 cost_time:429ms lr=1.1178e-04 total_loss:2.4714\n",
      "global_steps:29 epoch:1 steps:29/5011 cls_loss:0.8051 cnt_loss:0.7176 reg_loss:0.9994 cost_time:423ms lr=1.1577e-04 total_loss:2.5220\n",
      "global_steps:30 epoch:1 steps:30/5011 cls_loss:1.3025 cnt_loss:0.6650 reg_loss:1.0000 cost_time:377ms lr=1.1976e-04 total_loss:2.9675\n",
      "global_steps:31 epoch:1 steps:31/5011 cls_loss:0.9509 cnt_loss:0.6228 reg_loss:1.0000 cost_time:450ms lr=1.2375e-04 total_loss:2.5737\n",
      "global_steps:32 epoch:1 steps:32/5011 cls_loss:0.9180 cnt_loss:0.6495 reg_loss:1.0000 cost_time:407ms lr=1.2774e-04 total_loss:2.5675\n",
      "global_steps:33 epoch:1 steps:33/5011 cls_loss:1.0872 cnt_loss:0.7224 reg_loss:1.0002 cost_time:383ms lr=1.3174e-04 total_loss:2.8097\n",
      "global_steps:34 epoch:1 steps:34/5011 cls_loss:1.0665 cnt_loss:0.6689 reg_loss:1.0000 cost_time:420ms lr=1.3573e-04 total_loss:2.7354\n",
      "global_steps:35 epoch:1 steps:35/5011 cls_loss:1.0869 cnt_loss:0.6448 reg_loss:0.9999 cost_time:380ms lr=1.3972e-04 total_loss:2.7317\n",
      "global_steps:36 epoch:1 steps:36/5011 cls_loss:0.8726 cnt_loss:0.6255 reg_loss:0.9998 cost_time:430ms lr=1.4371e-04 total_loss:2.4980\n",
      "global_steps:37 epoch:1 steps:37/5011 cls_loss:0.8573 cnt_loss:0.6602 reg_loss:1.0000 cost_time:386ms lr=1.4770e-04 total_loss:2.5175\n",
      "global_steps:38 epoch:1 steps:38/5011 cls_loss:0.9655 cnt_loss:0.6697 reg_loss:0.9999 cost_time:422ms lr=1.5170e-04 total_loss:2.6351\n",
      "global_steps:39 epoch:1 steps:39/5011 cls_loss:1.0414 cnt_loss:0.6029 reg_loss:1.0000 cost_time:391ms lr=1.5569e-04 total_loss:2.6443\n",
      "global_steps:40 epoch:1 steps:40/5011 cls_loss:0.9400 cnt_loss:0.6495 reg_loss:1.0000 cost_time:381ms lr=1.5968e-04 total_loss:2.5895\n",
      "global_steps:41 epoch:1 steps:41/5011 cls_loss:0.9309 cnt_loss:0.6259 reg_loss:0.9998 cost_time:333ms lr=1.6367e-04 total_loss:2.5566\n",
      "global_steps:42 epoch:1 steps:42/5011 cls_loss:1.1563 cnt_loss:0.0000 reg_loss:0.0000 cost_time:342ms lr=1.6766e-04 total_loss:1.1563\n",
      "global_steps:43 epoch:1 steps:43/5011 cls_loss:0.8907 cnt_loss:0.6453 reg_loss:1.0000 cost_time:448ms lr=1.7166e-04 total_loss:2.5359\n",
      "global_steps:44 epoch:1 steps:44/5011 cls_loss:1.0476 cnt_loss:0.6459 reg_loss:0.9999 cost_time:381ms lr=1.7565e-04 total_loss:2.6935\n",
      "global_steps:45 epoch:1 steps:45/5011 cls_loss:1.2912 cnt_loss:0.6382 reg_loss:1.0000 cost_time:380ms lr=1.7964e-04 total_loss:2.9294\n",
      "global_steps:46 epoch:1 steps:46/5011 cls_loss:1.1011 cnt_loss:0.6665 reg_loss:1.0000 cost_time:436ms lr=1.8363e-04 total_loss:2.7675\n",
      "global_steps:47 epoch:1 steps:47/5011 cls_loss:0.8166 cnt_loss:0.6341 reg_loss:1.0000 cost_time:482ms lr=1.8762e-04 total_loss:2.4507\n",
      "global_steps:48 epoch:1 steps:48/5011 cls_loss:0.7992 cnt_loss:0.6281 reg_loss:1.0000 cost_time:447ms lr=1.9162e-04 total_loss:2.4272\n",
      "global_steps:49 epoch:1 steps:49/5011 cls_loss:1.0571 cnt_loss:0.6566 reg_loss:0.9998 cost_time:369ms lr=1.9561e-04 total_loss:2.7134\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d48fa507ccd1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# 2 损失计算\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_boxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_classes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\envs\\torch1.1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-00001d3d234c>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcos_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m# 编码标签信息\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mtargets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_boxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_classes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;31m# 计算标签和预测信息间的损失\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\conda\\envs\\torch1.1\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\29-pedestrain\\FCOS-PyTorch-case2\\model\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mlevel_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcls_logits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnt_logits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_preds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             level_targets = self._gen_level_targets(level_out, gt_boxes, classes, self.strides[level],\n\u001b[1;32m---> 57\u001b[1;33m                                                     self.limit_range[level])\n\u001b[0m\u001b[0;32m     58\u001b[0m             \u001b[0mcls_targets_all_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel_targets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[0mcnt_targets_all_level\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel_targets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\29-pedestrain\\FCOS-PyTorch-case2\\model\\loss.py\u001b[0m in \u001b[0;36m_gen_level_targets\u001b[1;34m(self, out, gt_boxes, classes, stride, limit_range, sample_radiu_ratio)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mcls_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls_logits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# [batch_size,h,w,class_num]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mcoords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoords_fmap2orig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls_logits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgt_boxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# [h*w,2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mcls_logits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls_logits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# [batch_size,h*w,class_num]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = opt.epochs\n",
    "steps_per_epoch = len(train_dataset) // BATCH_SIZE\n",
    "TOTAL_STEPS = steps_per_epoch * EPOCHS\n",
    "WARMPUP_STEPS = 501\n",
    "\n",
    "GLOBAL_STEPS = 1\n",
    "LR_INIT = 2e-3\n",
    "LR_END = 2e-5\n",
    "\n",
    "for epoch in range(EPOCHS):  # 分轮次，，，\n",
    "    for epoch_step, data in enumerate(train_loader):  # ，，，分批次 开始训练\n",
    "        \n",
    "        # ============================== 拿到批次数据 =========================\n",
    "        batch_imgs, batch_boxes, batch_classes = data\n",
    "        batch_imgs = batch_imgs.cuda()\n",
    "        batch_boxes = batch_boxes.cuda()\n",
    "        batch_classes = batch_classes.cuda()\n",
    "        # =====================================================================\n",
    "        \n",
    "        \n",
    "        # ================================ 学习率调整 =========================\n",
    "        if GLOBAL_STEPS < WARMPUP_STEPS:\n",
    "            lr = float(GLOBAL_STEPS / WARMPUP_STEPS * LR_INIT)\n",
    "            for param in optimizer.param_groups:\n",
    "                param['lr'] = lr\n",
    "        if GLOBAL_STEPS == 20001:\n",
    "            lr = LR_INIT * 0.1\n",
    "            for param in optimizer.param_groups:\n",
    "                param['lr'] = lr\n",
    "        if GLOBAL_STEPS == 27001:\n",
    "            lr = LR_INIT * 0.01\n",
    "            for param in optimizer.param_groups:\n",
    "                param['lr'] = lr       \n",
    "        # ===================================================================   \n",
    "        \n",
    "        \n",
    "        # ============================ 网络参数更新 =========================\n",
    "        start_time = time.time()\n",
    "        # 1 梯度清理\n",
    "        optimizer.zero_grad()\n",
    "        # 2 损失计算\n",
    "        losses = model([batch_imgs, batch_boxes, batch_classes])\n",
    "        loss = losses[-1]\n",
    "        loss.mean().backward()\n",
    "        # 3 梯度回传更新网络参数\n",
    "        optimizer.step()\n",
    "        # =================================================================\n",
    "        \n",
    "        \n",
    "        # ============================ 显示训练信息 =========================\n",
    "        end_time = time.time()\n",
    "        cost_time = int((end_time - start_time) * 1000)\n",
    "        print(\n",
    "            \"global_steps:%d epoch:%d steps:%d/%d cls_loss:%.4f cnt_loss:%.4f reg_loss:%.4f cost_time:%dms lr=%.4e total_loss:%.4f\" % \\\n",
    "            (GLOBAL_STEPS, epoch + 1, epoch_step + 1, steps_per_epoch, losses[0].mean(), losses[1].mean(),\n",
    "             losses[2].mean(), cost_time, lr, loss.mean()))\n",
    "\n",
    "        GLOBAL_STEPS += 1\n",
    "        # ==================================================================\n",
    "    torch.save(model.state_dict(),\n",
    "               \"./checkpoint/model_{}.pth\".format(epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "torch1.1",
   "language": "python",
   "name": "torch1.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
