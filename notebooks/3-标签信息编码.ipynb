{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random \n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensor & Feature map**\n",
    "\n",
    "Tensor:(h, w, c)=(2,5,3) ;\n",
    "\n",
    "Feature map:(b, h, w, c)=(3,2,4,5)\n",
    "\n",
    "<img src=\"imgs/3-axis_front.png\" width=\"400\" height=\"400\" align=\"left\">\n",
    "\n",
    "<img src=\"imgs/4-axis_block.png\" width=\"300\" height=\"400\" align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 假设一张输入图片的标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 一个标签框的情况\n",
    "# gt_boxes = np.array([[[10, 12, 48, 60]]]) \n",
    "# 一个gt_box对应的类别标签\n",
    "# classes = np.array([[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of gt_box in one img: 2\n",
      "gt_boxes: torch.Size([1, 2, 4]) torch.float32\n",
      "classes: torch.Size([1, 2]) torch.int32\n"
     ]
    }
   ],
   "source": [
    "# 当前图片中有两个标签框的情况，每个框由4个坐标表示，设定batch_size=1,\n",
    "gt_boxes = np.array([[[10, 12, 48, 60],\n",
    "                      [10, 20, 40, 50]]]) \n",
    "# 这两个gt_box各自对应的类别\n",
    "classes = np.array([[2,4]])  # （batch_size, num_of_gtbox)\n",
    "m = gt_boxes.shape[1]; print('num of gt_box in one img:',m)  # 标签框个数\n",
    "\n",
    "# 转变numpy的ndarray的数据类型，到torch的tensor数据类型，\n",
    "gt_boxes = torch.from_numpy(gt_boxes)\n",
    "gt_boxes = gt_boxes.type(torch.float32)  # 转换张量的数值类型，方便后续计算\n",
    "classes = torch.from_numpy(classes)\n",
    "\n",
    "print('gt_boxes:', gt_boxes.shape, gt_boxes.dtype)\n",
    "print('classes:', classes.shape, classes.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这张图片输入模型后，模型输出的预测值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**假设网络有三层输出(h,w)大小依次为 （16，16） （8，8） （4，4）**\n",
    "\n",
    "batch_size = 1；  num_of_class = 5（即图中classification的通道数C=5）\n",
    "<img src=\"imgs/head_demo.png\" width=\"500\" height=\"400\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有的分类层\n",
    "cls_logits_all = [random.rand(1, 5, 16, 16),  # 第一层 \n",
    "                 random.rand(1, 5, 8, 8),     # 第二层\n",
    "                 random.rand(1, 5, 4, 4),]    # 第三层\n",
    "# 所有的中心度层\n",
    "cnt_logits_all = [random.rand(1, 1, 16, 16),  # 第一层 \n",
    "                 random.rand(1, 1, 8, 8),     # 第二层\n",
    "                 random.rand(1, 1, 4, 4),]    # 第三层\n",
    "# 所有的回归层\n",
    "reg_preds_all = [random.rand(1, 4, 16, 16),   # 第一层 \n",
    "                 random.rand(1, 4, 8, 8),     # 第二层\n",
    "                 random.rand(1, 4, 4, 4),]    # 第三层\n",
    "\n",
    "fcos_out = [cls_logits_all, cnt_logits_all, reg_preds_all]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**不同层的网络输出**\n",
    "\n",
    "每一层都包括 分类输出、中心度输出和坐标偏置输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_0_out = [cls_logits_all[0], cnt_logits_all[0], reg_preds_all[0]]  # 第一层\n",
    "level_1_out = [cls_logits_all[1], cnt_logits_all[1], reg_preds_all[1]]  # 第二层\n",
    "level_2_out = [cls_logits_all[2], cnt_logits_all[2], reg_preds_all[2]]  # 第三层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征图信息编码（映射/转换）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征图上格点坐标与原图坐标的映射(对应)关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以第三层的运算为例 \n",
    "cls_logits, cnt_logits, reg_preds = cls_logits_all[2], cnt_logits_all[2], reg_preds_all[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 1\n",
      "feature_map_hw: torch.Size([4, 4])\n",
      "class_num: 5\n",
      "torch.Size([1, 4, 4, 5]) torch.float64\n"
     ]
    }
   ],
   "source": [
    "# 看一下第三个输出层中分类分支特征图的数据形式\n",
    "cls_logits = torch.from_numpy(cls_logits)  # 将numpy格式数据转换成tensor\n",
    "cls_logits = cls_logits.permute(0, 2, 3, 1)  # [batch_size,h,w,class_num]\n",
    "\n",
    "batch_size = cls_logits.shape[0] ;print('batch_size:', batch_size)\n",
    "hw = cls_logits.shape[1:3]; print('feature_map_hw:', hw)  # 图像的高宽\n",
    "class_num = cls_logits.shape[3] ;print('class_num:', class_num)\n",
    "print(cls_logits.shape, cls_logits.dtype)  # 特征图上每一个grid是一个5维的向量  用来表示当前点的类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/shape.png\" width=\"300\" height=\"400\" align=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每个特征点都携带原图内一定范围(感受野)内图像的信息，但是这些图像信息没办法直接转换成位置信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.,  8.],\n",
       "        [24.,  8.],\n",
       "        [40.,  8.],\n",
       "        [56.,  8.],\n",
       "        [ 8., 24.],\n",
       "        [24., 24.],\n",
       "        [40., 24.],\n",
       "        [56., 24.],\n",
       "        [ 8., 40.],\n",
       "        [24., 40.],\n",
       "        [40., 40.],\n",
       "        [56., 40.],\n",
       "        [ 8., 56.],\n",
       "        [24., 56.],\n",
       "        [40., 56.],\n",
       "        [56., 56.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n",
       "<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 257.325 248.518125\" width=\"257.325pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       " <defs>\r\n",
       "  <style type=\"text/css\">\r\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\r\n",
       "  </style>\r\n",
       " </defs>\r\n",
       " <g id=\"figure_1\">\r\n",
       "  <g id=\"patch_1\">\r\n",
       "   <path d=\"M 0 248.518125 \r\n",
       "L 257.325 248.518125 \r\n",
       "L 257.325 0 \r\n",
       "L 0 0 \r\n",
       "z\r\n",
       "\" style=\"fill:none;\"/>\r\n",
       "  </g>\r\n",
       "  <g id=\"axes_1\">\r\n",
       "   <g id=\"patch_2\">\r\n",
       "    <path d=\"M 26.925 224.64 \r\n",
       "L 250.125 224.64 \r\n",
       "L 250.125 7.2 \r\n",
       "L 26.925 7.2 \r\n",
       "z\r\n",
       "\" style=\"fill:#ffffff;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"PathCollection_1\">\r\n",
       "    <defs>\r\n",
       "     <path d=\"M 0 3 \r\n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\n",
       "C 2.683901 1.55874 3 0.795609 3 0 \r\n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \r\n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \r\n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \r\n",
       "z\r\n",
       "\" id=\"m04c26ba640\" style=\"stroke:#1f77b4;\"/>\r\n",
       "    </defs>\r\n",
       "    <g clip-path=\"url(#p0cfd10b63c)\">\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"37.070455\" xlink:href=\"#m04c26ba640\" y=\"214.756364\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"104.706818\" xlink:href=\"#m04c26ba640\" y=\"214.756364\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"172.343182\" xlink:href=\"#m04c26ba640\" y=\"214.756364\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"239.979545\" xlink:href=\"#m04c26ba640\" y=\"214.756364\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"37.070455\" xlink:href=\"#m04c26ba640\" y=\"148.865455\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"104.706818\" xlink:href=\"#m04c26ba640\" y=\"148.865455\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"172.343182\" xlink:href=\"#m04c26ba640\" y=\"148.865455\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"239.979545\" xlink:href=\"#m04c26ba640\" y=\"148.865455\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"37.070455\" xlink:href=\"#m04c26ba640\" y=\"82.974545\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"104.706818\" xlink:href=\"#m04c26ba640\" y=\"82.974545\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"172.343182\" xlink:href=\"#m04c26ba640\" y=\"82.974545\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"239.979545\" xlink:href=\"#m04c26ba640\" y=\"82.974545\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"37.070455\" xlink:href=\"#m04c26ba640\" y=\"17.083636\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"104.706818\" xlink:href=\"#m04c26ba640\" y=\"17.083636\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"172.343182\" xlink:href=\"#m04c26ba640\" y=\"17.083636\"/>\r\n",
       "     <use style=\"fill:#1f77b4;stroke:#1f77b4;\" x=\"239.979545\" xlink:href=\"#m04c26ba640\" y=\"17.083636\"/>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_1\">\r\n",
       "    <g id=\"xtick_1\">\r\n",
       "     <g id=\"line2d_1\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L 0 3.5 \r\n",
       "\" id=\"mf23bb88b9b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.525\" xlink:href=\"#mf23bb88b9b\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_1\">\r\n",
       "      <!-- 10 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 12.40625 8.296875 \r\n",
       "L 28.515625 8.296875 \r\n",
       "L 28.515625 63.921875 \r\n",
       "L 10.984375 60.40625 \r\n",
       "L 10.984375 69.390625 \r\n",
       "L 28.421875 72.90625 \r\n",
       "L 38.28125 72.90625 \r\n",
       "L 38.28125 8.296875 \r\n",
       "L 54.390625 8.296875 \r\n",
       "L 54.390625 0 \r\n",
       "L 12.40625 0 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-49\"/>\r\n",
       "       <path d=\"M 31.78125 66.40625 \r\n",
       "Q 24.171875 66.40625 20.328125 58.90625 \r\n",
       "Q 16.5 51.421875 16.5 36.375 \r\n",
       "Q 16.5 21.390625 20.328125 13.890625 \r\n",
       "Q 24.171875 6.390625 31.78125 6.390625 \r\n",
       "Q 39.453125 6.390625 43.28125 13.890625 \r\n",
       "Q 47.125 21.390625 47.125 36.375 \r\n",
       "Q 47.125 51.421875 43.28125 58.90625 \r\n",
       "Q 39.453125 66.40625 31.78125 66.40625 \r\n",
       "z\r\n",
       "M 31.78125 74.21875 \r\n",
       "Q 44.046875 74.21875 50.515625 64.515625 \r\n",
       "Q 56.984375 54.828125 56.984375 36.375 \r\n",
       "Q 56.984375 17.96875 50.515625 8.265625 \r\n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \r\n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \r\n",
       "Q 6.59375 17.96875 6.59375 36.375 \r\n",
       "Q 6.59375 54.828125 13.0625 64.515625 \r\n",
       "Q 19.53125 74.21875 31.78125 74.21875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-48\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(39.1625 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_2\">\r\n",
       "     <g id=\"line2d_2\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"87.797727\" xlink:href=\"#mf23bb88b9b\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_2\">\r\n",
       "      <!-- 20 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 19.1875 8.296875 \r\n",
       "L 53.609375 8.296875 \r\n",
       "L 53.609375 0 \r\n",
       "L 7.328125 0 \r\n",
       "L 7.328125 8.296875 \r\n",
       "Q 12.9375 14.109375 22.625 23.890625 \r\n",
       "Q 32.328125 33.6875 34.8125 36.53125 \r\n",
       "Q 39.546875 41.84375 41.421875 45.53125 \r\n",
       "Q 43.3125 49.21875 43.3125 52.78125 \r\n",
       "Q 43.3125 58.59375 39.234375 62.25 \r\n",
       "Q 35.15625 65.921875 28.609375 65.921875 \r\n",
       "Q 23.96875 65.921875 18.8125 64.3125 \r\n",
       "Q 13.671875 62.703125 7.8125 59.421875 \r\n",
       "L 7.8125 69.390625 \r\n",
       "Q 13.765625 71.78125 18.9375 73 \r\n",
       "Q 24.125 74.21875 28.421875 74.21875 \r\n",
       "Q 39.75 74.21875 46.484375 68.546875 \r\n",
       "Q 53.21875 62.890625 53.21875 53.421875 \r\n",
       "Q 53.21875 48.921875 51.53125 44.890625 \r\n",
       "Q 49.859375 40.875 45.40625 35.40625 \r\n",
       "Q 44.1875 33.984375 37.640625 27.21875 \r\n",
       "Q 31.109375 20.453125 19.1875 8.296875 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-50\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(81.435227 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_3\">\r\n",
       "     <g id=\"line2d_3\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"130.070455\" xlink:href=\"#mf23bb88b9b\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_3\">\r\n",
       "      <!-- 30 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 40.578125 39.3125 \r\n",
       "Q 47.65625 37.796875 51.625 33 \r\n",
       "Q 55.609375 28.21875 55.609375 21.1875 \r\n",
       "Q 55.609375 10.40625 48.1875 4.484375 \r\n",
       "Q 40.765625 -1.421875 27.09375 -1.421875 \r\n",
       "Q 22.515625 -1.421875 17.65625 -0.515625 \r\n",
       "Q 12.796875 0.390625 7.625 2.203125 \r\n",
       "L 7.625 11.71875 \r\n",
       "Q 11.71875 9.328125 16.59375 8.109375 \r\n",
       "Q 21.484375 6.890625 26.8125 6.890625 \r\n",
       "Q 36.078125 6.890625 40.9375 10.546875 \r\n",
       "Q 45.796875 14.203125 45.796875 21.1875 \r\n",
       "Q 45.796875 27.640625 41.28125 31.265625 \r\n",
       "Q 36.765625 34.90625 28.71875 34.90625 \r\n",
       "L 20.21875 34.90625 \r\n",
       "L 20.21875 43.015625 \r\n",
       "L 29.109375 43.015625 \r\n",
       "Q 36.375 43.015625 40.234375 45.921875 \r\n",
       "Q 44.09375 48.828125 44.09375 54.296875 \r\n",
       "Q 44.09375 59.90625 40.109375 62.90625 \r\n",
       "Q 36.140625 65.921875 28.71875 65.921875 \r\n",
       "Q 24.65625 65.921875 20.015625 65.03125 \r\n",
       "Q 15.375 64.15625 9.8125 62.3125 \r\n",
       "L 9.8125 71.09375 \r\n",
       "Q 15.4375 72.65625 20.34375 73.4375 \r\n",
       "Q 25.25 74.21875 29.59375 74.21875 \r\n",
       "Q 40.828125 74.21875 47.359375 69.109375 \r\n",
       "Q 53.90625 64.015625 53.90625 55.328125 \r\n",
       "Q 53.90625 49.265625 50.4375 45.09375 \r\n",
       "Q 46.96875 40.921875 40.578125 39.3125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-51\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(123.707955 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-51\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_4\">\r\n",
       "     <g id=\"line2d_4\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"172.343182\" xlink:href=\"#mf23bb88b9b\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_4\">\r\n",
       "      <!-- 40 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 37.796875 64.3125 \r\n",
       "L 12.890625 25.390625 \r\n",
       "L 37.796875 25.390625 \r\n",
       "z\r\n",
       "M 35.203125 72.90625 \r\n",
       "L 47.609375 72.90625 \r\n",
       "L 47.609375 25.390625 \r\n",
       "L 58.015625 25.390625 \r\n",
       "L 58.015625 17.1875 \r\n",
       "L 47.609375 17.1875 \r\n",
       "L 47.609375 0 \r\n",
       "L 37.796875 0 \r\n",
       "L 37.796875 17.1875 \r\n",
       "L 4.890625 17.1875 \r\n",
       "L 4.890625 26.703125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-52\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(165.980682 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"xtick_5\">\r\n",
       "     <g id=\"line2d_5\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"214.615909\" xlink:href=\"#mf23bb88b9b\" y=\"224.64\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_5\">\r\n",
       "      <!-- 50 -->\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 10.796875 72.90625 \r\n",
       "L 49.515625 72.90625 \r\n",
       "L 49.515625 64.59375 \r\n",
       "L 19.828125 64.59375 \r\n",
       "L 19.828125 46.734375 \r\n",
       "Q 21.96875 47.46875 24.109375 47.828125 \r\n",
       "Q 26.265625 48.1875 28.421875 48.1875 \r\n",
       "Q 40.625 48.1875 47.75 41.5 \r\n",
       "Q 54.890625 34.8125 54.890625 23.390625 \r\n",
       "Q 54.890625 11.625 47.5625 5.09375 \r\n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \r\n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \r\n",
       "Q 12.796875 0.140625 7.71875 1.703125 \r\n",
       "L 7.71875 11.625 \r\n",
       "Q 12.109375 9.234375 16.796875 8.0625 \r\n",
       "Q 21.484375 6.890625 26.703125 6.890625 \r\n",
       "Q 35.15625 6.890625 40.078125 11.328125 \r\n",
       "Q 45.015625 15.765625 45.015625 23.390625 \r\n",
       "Q 45.015625 31 40.078125 35.4375 \r\n",
       "Q 35.15625 39.890625 26.703125 39.890625 \r\n",
       "Q 22.75 39.890625 18.8125 39.015625 \r\n",
       "Q 14.890625 38.140625 10.796875 36.28125 \r\n",
       "z\r\n",
       "\" id=\"DejaVuSans-53\"/>\r\n",
       "      </defs>\r\n",
       "      <g transform=\"translate(208.253409 239.238437)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"matplotlib.axis_2\">\r\n",
       "    <g id=\"ytick_1\">\r\n",
       "     <g id=\"line2d_6\">\r\n",
       "      <defs>\r\n",
       "       <path d=\"M 0 0 \r\n",
       "L -3.5 0 \r\n",
       "\" id=\"mcaddf8658f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n",
       "      </defs>\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mcaddf8658f\" y=\"206.52\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_6\">\r\n",
       "      <!-- 10 -->\r\n",
       "      <g transform=\"translate(7.2 210.319219)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_2\">\r\n",
       "     <g id=\"line2d_7\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mcaddf8658f\" y=\"165.338182\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_7\">\r\n",
       "      <!-- 20 -->\r\n",
       "      <g transform=\"translate(7.2 169.137401)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_3\">\r\n",
       "     <g id=\"line2d_8\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mcaddf8658f\" y=\"124.156364\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_8\">\r\n",
       "      <!-- 30 -->\r\n",
       "      <g transform=\"translate(7.2 127.955582)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-51\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_4\">\r\n",
       "     <g id=\"line2d_9\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mcaddf8658f\" y=\"82.974545\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_9\">\r\n",
       "      <!-- 40 -->\r\n",
       "      <g transform=\"translate(7.2 86.773764)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "    <g id=\"ytick_5\">\r\n",
       "     <g id=\"line2d_10\">\r\n",
       "      <g>\r\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#mcaddf8658f\" y=\"41.792727\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "     <g id=\"text_10\">\r\n",
       "      <!-- 50 -->\r\n",
       "      <g transform=\"translate(7.2 45.591946)scale(0.1 -0.1)\">\r\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\r\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n",
       "      </g>\r\n",
       "     </g>\r\n",
       "    </g>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_3\">\r\n",
       "    <path d=\"M 26.925 224.64 \r\n",
       "L 26.925 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_4\">\r\n",
       "    <path d=\"M 250.125 224.64 \r\n",
       "L 250.125 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_5\">\r\n",
       "    <path d=\"M 26.925 224.64 \r\n",
       "L 250.125 224.64 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "   <g id=\"patch_6\">\r\n",
       "    <path d=\"M 26.925 7.2 \r\n",
       "L 250.125 7.2 \r\n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n",
       "   </g>\r\n",
       "  </g>\r\n",
       " </g>\r\n",
       " <defs>\r\n",
       "  <clipPath id=\"p0cfd10b63c\">\r\n",
       "   <rect height=\"217.44\" width=\"223.2\" x=\"26.925\" y=\"7.2\"/>\r\n",
       "  </clipPath>\r\n",
       " </defs>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def coords_fmap2orig(feature, stride=16):  # 特征图上的grid对应于原图的位置\n",
    "    '''\n",
    "    transfor one fmap coords to orig coords\n",
    "    Args:\n",
    "        featurn [batch_size,h,w,c]\n",
    "        stride int\n",
    "    Returns ：\n",
    "        coords [n,2]\n",
    "    '''\n",
    "    h, w = feature.shape[1:3]  \n",
    "    # h, w = 8, 8 # 为演示方便，我们使用尺寸为（4，4）的特征图\n",
    "    shifts_x = torch.arange(0, w * stride, stride, dtype=torch.float32)\n",
    "    shifts_y = torch.arange(0, h * stride, stride, dtype=torch.float32)\n",
    "    shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)\n",
    "    shift_x = torch.reshape(shift_x, [-1])\n",
    "    shift_y = torch.reshape(shift_y, [-1])\n",
    "    coords = torch.stack([shift_x, shift_y], -1) + (stride // 2)  # 中心点偏置\n",
    "    # 可视化一下，看看\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.scatter(coords[:,0], coords[:,1])\n",
    "    # plt.savefig('grid.png')\n",
    "    return coords\n",
    "\n",
    "coords = coords_fmap2orig(cls_logits)\n",
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/perception field.png\" width=\"700\" height=\"400\" align=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用形状转换，将特征图降维,(姑且将特征图上的每一个格点称为特征点，一个图像的像素点有3维，rgb，一个特征图的特征点按任务需求设定不同维度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 5])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cls_logits \n",
    "cls_logits = cls_logits.reshape((batch_size, -1, class_num))  # [batch_size,h*w,class_num]\n",
    "cls_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/reshape1.png\" width=\"600\" height=\"400\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将三阶张量，转换成二阶的张量（矩阵）方便制作监督标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 reshape cnt\n",
    "cnt_logits = torch.from_numpy(cnt_logits)\n",
    "cnt_logits = cnt_logits.permute(0, 2, 3, 1)   \n",
    "cnt_logits = cnt_logits.reshape((batch_size, -1, 1))    # [batch_size,h*w,1]\n",
    "cnt_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 4])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 reshape reg\n",
    "reg_preds = torch.from_numpy(reg_preds)\n",
    "reg_preds = reg_preds.permute(0, 2, 3, 1)\n",
    "reg_preds = reg_preds.reshape((batch_size, -1, 4))  #  # [batch_size,h*w,4]\n",
    "reg_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 转换后特征图的形状特征\n",
    "h_mul_w = cls_logits.shape[1] \n",
    "h_mul_w  # h*w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找特征图上的格点与标签框gtbox边缘的偏置关系\n",
    "\n",
    "&emsp;&emsp;特征图上的`特征点`，映射到原图上的`位置`，我们称之为`锚点（anchor point)`,如下图中的蓝色点:\n",
    "\n",
    "&emsp;&emsp;特征图上feature_grid的坐标（x_fea,y_fea）先映射到原图上(x_anc, y_anc), 然后找点(x_anc, y_anc)与gtbox坐标(x_min,y_min, x_max,y_max)的偏置关系:当前点到框的各边的距离(l, t, r, b)\n",
    "\n",
    "<img src=\"imgs/tensor2fea2img.png\" width=\"900\" height=\"400\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**思考1：** 如何判断 anchor_point 是不是在标签框内呢？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**思考2**：一个标签框内有多少个像素点？anchor_point 和 pixel 有什么关系呢？\n",
    "\n",
    "((l + r) * (t + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8., 24., 40., 56.,  8., 24., 40., 56.,  8., 24., 40., 56.,  8., 24.,\n",
      "        40., 56.])\n",
      "tensor([ 8.,  8.,  8.,  8., 24., 24., 24., 24., 40., 40., 40., 40., 56., 56.,\n",
      "        56., 56.])\n"
     ]
    }
   ],
   "source": [
    "x = coords[:, 0] ; print(x)\n",
    "y = coords[:, 1] ; print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": false,
    "scrolled": true
   },
   "source": [
    "**知识点：**\n",
    "\n",
    "```python\n",
    "gt_boxes = np.array([[[10, 12, 48, 60],\n",
    "                      [10, 20, 40, 50]]]) \n",
    "gt_boxes[..., 0]  # 取第一列  所有gt框的xmin\n",
    "\n",
    ">>> [[10, 10]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2., -2.],\n",
       "         [14., 14.],\n",
       "         [30., 30.],\n",
       "         [46., 46.],\n",
       "         [-2., -2.],\n",
       "         [14., 14.],\n",
       "         [30., 30.],\n",
       "         [46., 46.],\n",
       "         [-2., -2.],\n",
       "         [14., 14.],\n",
       "         [30., 30.],\n",
       "         [46., 46.],\n",
       "         [-2., -2.],\n",
       "         [14., 14.],\n",
       "         [30., 30.],\n",
       "         [46., 46.]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1, h*w, 1] - [batch_size, 1, m] --> [batch_size, h*w, m]\n",
    "# 所有锚点的横坐标到标签框左边的距离\n",
    "l_off = x[None, :, None] - gt_boxes[..., 0][:, None, :]   # None 增加维度用的\n",
    "l_off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/sub.png\" width=\"400\" height=\"400\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# 所有锚点的纵坐标到标签框顶部的距离\n",
    "t_off = y[None, :, None] - gt_boxes[..., 1][:, None, :]\n",
    "# 标签框右边到所有锚点横坐标的距离\n",
    "r_off = gt_boxes[..., 2][:, None, :] - x[None, :, None]\n",
    "# 标签框下边到所有锚点纵坐标的距离\n",
    "b_off = gt_boxes[..., 3][:, None, :] - y[None, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 2, 4])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ltrb_off = torch.stack([l_off, t_off, r_off, b_off], dim=-1)  # [batch_size,h*w,m,4]\n",
    "ltrb_off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ -2.,  -4.,  40.,  52.],\n",
       "          [ -2., -12.,  32.,  42.]],\n",
       "\n",
       "         [[ 14.,  -4.,  24.,  52.],\n",
       "          [ 14., -12.,  16.,  42.]],\n",
       "\n",
       "         [[ 30.,  -4.,   8.,  52.],\n",
       "          [ 30., -12.,   0.,  42.]],\n",
       "\n",
       "         [[ 46.,  -4.,  -8.,  52.],\n",
       "          [ 46., -12., -16.,  42.]],\n",
       "\n",
       "         [[ -2.,  12.,  40.,  36.],\n",
       "          [ -2.,   4.,  32.,  26.]],\n",
       "\n",
       "         [[ 14.,  12.,  24.,  36.],\n",
       "          [ 14.,   4.,  16.,  26.]],\n",
       "\n",
       "         [[ 30.,  12.,   8.,  36.],\n",
       "          [ 30.,   4.,   0.,  26.]],\n",
       "\n",
       "         [[ 46.,  12.,  -8.,  36.],\n",
       "          [ 46.,   4., -16.,  26.]],\n",
       "\n",
       "         [[ -2.,  28.,  40.,  20.],\n",
       "          [ -2.,  20.,  32.,  10.]],\n",
       "\n",
       "         [[ 14.,  28.,  24.,  20.],\n",
       "          [ 14.,  20.,  16.,  10.]],\n",
       "\n",
       "         [[ 30.,  28.,   8.,  20.],\n",
       "          [ 30.,  20.,   0.,  10.]],\n",
       "\n",
       "         [[ 46.,  28.,  -8.,  20.],\n",
       "          [ 46.,  20., -16.,  10.]],\n",
       "\n",
       "         [[ -2.,  44.,  40.,   4.],\n",
       "          [ -2.,  36.,  32.,  -6.]],\n",
       "\n",
       "         [[ 14.,  44.,  24.,   4.],\n",
       "          [ 14.,  36.,  16.,  -6.]],\n",
       "\n",
       "         [[ 30.,  44.,   8.,   4.],\n",
       "          [ 30.,  36.,   0.,  -6.]],\n",
       "\n",
       "         [[ 46.,  44.,  -8.,   4.],\n",
       "          [ 46.,  36., -16.,  -6.]]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16个锚点(x_img,y_img)与俩个gt_boxes(x_min,y_min,x_max,y_max)的偏置关系\n",
    "ltrb_off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择feature map上的正负样本点\n",
    "&emsp;&emsp;对于feature map上的各个点（x_fea,y_fea），只要这个点对应的(x_anc, y_anc)落到了gt bbox(x_min,y_min, x_max,y_max)区域中，那么这个点就是正样本；而如果这个点多在多个bbox中，那个这个点就是模糊样本，目前采用面积最小的bbox作为这个点的回归目标。目标框的回归参数是：当前点到框的各边的距离(l, t, r, b)。\n",
    "<img src=\"imgs/ancher free.png\" width=\"500\" height=\"400\" align=\"bottom\">\n",
    ">```python\n",
    "l_off = x[None, :, None] - gt_boxes[..., 0][:, None, :]\n",
    "t_off = y[None, :, None] - gt_boxes[..., 1][:, None, :]\n",
    "r_off = gt_boxes[..., 2][:, None, :] - x[None, :, None]\n",
    "b_off = gt_boxes[..., 3][:, None, :] - y[None, :, None]\n",
    "ltrb_off = torch.stack([l_off, t_off, r_off, b_off], dim=-1)  # [batch_size,h*w,m,4]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [batch_size, h*w, m, 4] --> # [batch_size, h*w, m]  m represents the number of gt boxes\n",
    "off_min = torch.min(ltrb_off, dim=-1)[0]  # [batch_size, h*w, m]\n",
    "off_max = torch.max(ltrb_off, dim=-1)[0]  # [batch_size, h*w, m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [1, 1],\n",
       "         [1, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [1, 1],\n",
       "         [1, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         [0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_min > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_in_gtboxes = off_min > 0  # 满足条件的为真 1 保留"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_in_level = (off_max > 32) & (off_max <= 64)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/scale.png\" width=\"600\" height=\"400\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/level_scale2.png\" width=\"400\" height=\"400\" align=\"left\">\n",
    "<img src=\"imgs/level_scale1.png\" width=\"400\" height=\"400\" align=\"\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找正样本点与gtbox中心的偏置关系\n",
    "<img src=\"imgs/ancher free.png\" width=\"500\" height=\"400\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[29., 25.]])\n",
      "tensor([[36., 35.]])\n"
     ]
    }
   ],
   "source": [
    "# 计算gt_box的中心  我们假设有两个gt box \n",
    "gt_center_x = (gt_boxes[..., 0] + gt_boxes[..., 2]) / 2  ; print(gt_center_x)\n",
    "gt_center_y = (gt_boxes[..., 1] + gt_boxes[..., 3]) / 2 ; print(gt_center_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_box 中心点与 feat_map grid 间的偏置关系\n",
    "# | x - gt_center_x | x方向上的距离\n",
    "# | y - gt_center_y | y方向上的距离\n",
    "c_l_off = x[None, :, None] - gt_center_x[:, None, :]  # [1,h*w,1]-[batch_size,1,m]-->[batch_size,h*w,m]\n",
    "c_r_off = gt_center_x[:, None, :] - x[None, :, None]\n",
    "\n",
    "c_t_off = y[None, :, None] - gt_center_y[:, None, :]\n",
    "c_b_off = gt_center_y[:, None, :] - y[None, :, None]\n",
    "\n",
    "\n",
    "c_ltrb_off = torch.stack([c_l_off, c_t_off, c_r_off, c_b_off], dim=-1)  # [batch_size,h*w,m,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[28., 27.],\n",
       "         [28., 27.],\n",
       "         [28., 27.],\n",
       "         [28., 31.],\n",
       "         [21., 17.],\n",
       "         [12., 11.],\n",
       "         [12., 15.],\n",
       "         [27., 31.],\n",
       "         [21., 17.],\n",
       "         [ 5.,  5.],\n",
       "         [11., 15.],\n",
       "         [27., 31.],\n",
       "         [21., 21.],\n",
       "         [20., 21.],\n",
       "         [20., 21.],\n",
       "         [27., 31.]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 相当于取两点之间的距离了\n",
    "c_off_max = torch.max(c_ltrb_off, dim=-1)[0]  # 相对于gt_box center 偏的最远的grid\n",
    "c_off_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [0, 0],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [0, 0],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [1, 1],\n",
       "         [0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_center = c_off_max < 1.5 * 16  # 1 * stride / 1.5*stride\n",
    "mask_center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/center.png\" width=\"400\" height=\"400\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [1, 0],\n",
      "         [1, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [0, 0],\n",
      "         [1, 0],\n",
      "         [1, 0],\n",
      "         [0, 0]]], dtype=torch.uint8) torch.Size([1, 16, 2])\n"
     ]
    }
   ],
   "source": [
    "mask_pos = mask_in_gtboxes & mask_in_level & mask_center \n",
    "print(mask_pos,mask_pos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据gt_box面积分配模糊正样本点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于feature map上的各个点（x_fea,y_fea），只要这个点对应的(x_img, y_img)落到了gt bbox(x_min,y_min, x_max,y_max)区域中，那么这个点就是正样本；而如果这个点出现在多个bbox中，那么这个点就是模糊样本，目前采用面积最小的bbox作为这个点的回归目标。\n",
    "<img src=\"imgs/ancher free.png\" width=\"500\" height=\"400\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.],\n",
      "         [1824.,  900.]]])\n"
     ]
    }
   ],
   "source": [
    "areas = (ltrb_off[..., 0] + ltrb_off[..., 2]) * (ltrb_off[..., 1] + ltrb_off[..., 3])  # [batch_size,h*w,m]\n",
    "print(areas)  # 框的面积值 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[99999., 99999.],\n",
       "         [99999., 99999.],\n",
       "         [99999., 99999.],\n",
       "         [99999., 99999.],\n",
       "         [99999., 99999.],\n",
       "         [ 1824., 99999.],\n",
       "         [ 1824., 99999.],\n",
       "         [99999., 99999.],\n",
       "         [99999., 99999.],\n",
       "         [99999., 99999.],\n",
       "         [99999., 99999.],\n",
       "         [99999., 99999.],\n",
       "         [99999., 99999.],\n",
       "         [ 1824., 99999.],\n",
       "         [ 1824., 99999.],\n",
       "         [99999., 99999.]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas[~mask_pos] = 99999 # 初始化非样本点 \n",
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas_min_ind = torch.min(areas, dim=-1)[1]  # [batch_size,h*w]\n",
    "areas_min_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [1],\n",
       "         [0],\n",
       "         [0],\n",
       "         [1]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas_min_ind.unsqueeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0],\n",
       "         [0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(areas, dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [0, 1],\n",
       "         [1, 0],\n",
       "         [1, 0],\n",
       "         [0, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成独热向量\n",
    "index = torch.zeros_like(areas, dtype=torch.uint8).scatter_(-1, \n",
    "                                                    areas_min_ind.unsqueeze(dim=-1),  # 增加一个维度\n",
    "                                                    1)\n",
    "print(index.shape)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16, 2, 4])\n",
      "torch.Size([16, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -2., -12.,  32.,  42.],\n",
       "        [ 14., -12.,  16.,  42.],\n",
       "        [ 30., -12.,   0.,  42.],\n",
       "        [ 46., -12., -16.,  42.],\n",
       "        [ -2.,   4.,  32.,  26.],\n",
       "        [ 14.,  12.,  24.,  36.],\n",
       "        [ 30.,  12.,   8.,  36.],\n",
       "        [ 46.,   4., -16.,  26.],\n",
       "        [ -2.,  20.,  32.,  10.],\n",
       "        [ 14.,  20.,  16.,  10.],\n",
       "        [ 30.,  20.,   0.,  10.],\n",
       "        [ 46.,  20., -16.,  10.],\n",
       "        [ -2.,  36.,  32.,  -6.],\n",
       "        [ 14.,  44.,  24.,   4.],\n",
       "        [ 30.,  44.,   8.,   4.],\n",
       "        [ 46.,  36., -16.,  -6.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定一下面积最小的那个框，特征图上的每个格点对应到它所属的面积最小的gt_box\n",
    "print(ltrb_off.shape)\n",
    "reg_targets = ltrb_off[index]  # [batch_size*h*w, 4]\n",
    "print(reg_targets.shape)\n",
    "reg_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#       [[[[ -2.,  -4.,  40.,  52.],\n",
    "#           [ -2., -12.,  32.,  42.]],\n",
    "\n",
    "#          [[ 14.,  -4.,  24.,  52.],\n",
    "#           [ 14., -12.,  16.,  42.]],\n",
    "\n",
    "#          [[ 30.,  -4.,   8.,  52.],\n",
    "#           [ 30., -12.,   0.,  42.]],\n",
    "\n",
    "#          [[ 46.,  -4.,  -8.,  52.],\n",
    "#           [ 46., -12., -16.,  42.]],\n",
    "\n",
    "#          [[ -2.,  12.,  40.,  36.],\n",
    "#           [ -2.,   4.,  32.,  26.]],\n",
    "\n",
    "#          [[ 14.,  12.,  24.,  36.],\n",
    "#           [ 14.,   4.,  16.,  26.]],\n",
    "\n",
    "#          [[ 30.,  12.,   8.,  36.],\n",
    "#           [ 30.,   4.,   0.,  26.]],\n",
    "\n",
    "#          [[ 46.,  12.,  -8.,  36.],\n",
    "#           [ 46.,   4., -16.,  26.]],\n",
    "\n",
    "#          [[ -2.,  28.,  40.,  20.],\n",
    "#           [ -2.,  20.,  32.,  10.]],\n",
    "\n",
    "#          [[ 14.,  28.,  24.,  20.],\n",
    "#           [ 14.,  20.,  16.,  10.]],\n",
    "\n",
    "#          [[ 30.,  28.,   8.,  20.],\n",
    "#           [ 30.,  20.,   0.,  10.]],\n",
    "\n",
    "#          [[ 46.,  28.,  -8.,  20.],\n",
    "#           [ 46.,  20., -16.,  10.]],\n",
    "\n",
    "#          [[ -2.,  44.,  40.,   4.],\n",
    "#           [ -2.,  36.,  32.,  -6.]],\n",
    "\n",
    "#          [[ 14.,  44.,  24.,   4.],\n",
    "#           [ 14.,  36.,  16.,  -6.]],\n",
    "\n",
    "#          [[ 30.,  44.,   8.,   4.],\n",
    "#           [ 30.,  36.,   0.,  -6.]],\n",
    "\n",
    "#          [[ 46.,  44.,  -8.,   4.],\n",
    "#           [ 46.,  36., -16.,  -6.]]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4],\n",
       "         [2, 4]]], dtype=torch.int32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = torch.broadcast_tensors(classes[:, None, :], areas.long())[0] # areas.long() 转换area的数值类型\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 4], dtype=torch.int32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select = torch.zeros_like(areas, dtype=torch.uint8).scatter_(-1, areas_min_ind.unsqueeze(dim=-1), 1)\n",
    "cls_targets = classes[select]\n",
    "cls_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [cnt_targets 在做什么?](https://blog.csdn.net/shanglianlm/article/details/89007219)\n",
    "**centerness**\n",
    "\n",
    "&emsp;&emsp;通过center-ness来度量当前位置和物体中心间的距离，即FCOS将点的坐标在目标中的位置因素也考虑进来，越靠近中间权重越大。\n",
    "<img src=\"imgs/centerness.jpg\" width=\"500\" height=\"400\" align=\"bottom\">\n",
    "\n",
    "\n",
    "&emsp;&emsp;在训练的过程中通过损失函数，我们会约束center-ness的值，使得其接近于0，使得分布在目标位置边缘的低质量框能够尽可能的靠近中心。在最终使用该网络的过程中，非极大值抑制(NMS)就可以轻松滤除这些低质量的边界框，提高检测性能。\n",
    "<img src=\"imgs/equation3.png\" width=\"500\" height=\"400\" align=\"bottom\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -2.,  14.,   0., -16.,  -2.,  14.,   8., -16.,  -2.,  14.,   0., -16.,\n",
      "         -2.,  14.,   8., -16.])\n",
      "tensor([32., 16., 30., 46., 32., 24., 30., 46., 32., 16., 30., 46., 32., 24.,\n",
      "        30., 46.])\n"
     ]
    }
   ],
   "source": [
    "left_right_min = torch.min(reg_targets[..., 0], reg_targets[..., 2]) ; print(left_right_min)\n",
    "left_right_max = torch.max(reg_targets[..., 0], reg_targets[..., 2]) ; print(left_right_max)\n",
    "top_bottom_min = torch.min(reg_targets[..., 1], reg_targets[..., 3])\n",
    "top_bottom_max = torch.max(reg_targets[..., 1], reg_targets[..., 3])\n",
    "# 上面的值拿来计算中心目标\n",
    "cnt_targets = ((left_right_min * top_bottom_min) / (left_right_max * top_bottom_max + 1e-4)).sqrt().unsqueeze(\n",
    "    dim=-1)  # [batch_size,h*w,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1336],\n",
       "        [   nan],\n",
       "        [-0.0000],\n",
       "        [0.3152],\n",
       "        [   nan],\n",
       "        [0.4410],\n",
       "        [0.2981],\n",
       "        [   nan],\n",
       "        [   nan],\n",
       "        [0.6614],\n",
       "        [0.0000],\n",
       "        [   nan],\n",
       "        [0.1021],\n",
       "        [0.2303],\n",
       "        [0.1557],\n",
       "        [0.2408]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据mask制作taragets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mask_pos = mask_in_gtboxes & mask_in_level & mask_center  # (bs, h*w, n_gt_boxes)  \n",
    "mask_pos.long().sum(dim=-1)  # [batch_size,h*w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pos_2 = mask_pos.long().sum(dim=-1)  # [batch_size,h*w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_pos_2 = mask_pos_2 >= 1\n",
    "mask_pos_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 4, 4, 4, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 4], dtype=torch.int32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0], dtype=torch.int32)\n",
      "tensor([[-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.4410],\n",
      "        [ 0.2981],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [-1.0000],\n",
      "        [ 0.2303],\n",
      "        [ 0.1557],\n",
      "        [-1.0000]])\n",
      "tensor([[-1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1.],\n",
      "        [14., 12., 24., 36.],\n",
      "        [30., 12.,  8., 36.],\n",
      "        [-1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1.],\n",
      "        [-1., -1., -1., -1.],\n",
      "        [14., 44., 24.,  4.],\n",
      "        [30., 44.,  8.,  4.],\n",
      "        [-1., -1., -1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "# 对于只有一个gt_box的情况\n",
    "cls_targets[~mask_pos_2.squeeze()] = 0   # [batch_size,h*w,1]\n",
    "cnt_targets[~mask_pos_2.squeeze()] = -1  \n",
    "reg_targets[~mask_pos_2.squeeze()] = -1\n",
    "\n",
    "print(cls_targets)\n",
    "print(cnt_targets)\n",
    "print(reg_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总体函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "  def _gen_level_targets(out, gt_boxes, classes, stride, limit_range, sample_radiu_ratio=1.5):\n",
    "        '''\n",
    "        Args  \n",
    "        out list contains [[batch_size,class_num,h,w],[batch_size,1,h,w],[batch_size,4,h,w]]  \n",
    "        gt_boxes [batch_size,m,4]  \n",
    "        classes [batch_size,m]  \n",
    "        stride int  \n",
    "        limit_range list [min,max]  \n",
    "        Returns  \n",
    "        cls_targets,cnt_targets,reg_targets\n",
    "        '''\n",
    "        # 1 三个同一层的分类 中心 定位的 预测数据\n",
    "        cls_logits, cnt_logits, reg_preds = out\n",
    "        batch_size = cls_logits.shape[0]\n",
    "        class_num = cls_logits.shape[1]\n",
    "        # 2 一个图片有多少个标签框\n",
    "        m = gt_boxes.shape[1]\n",
    "        # 3 reshape (batch_size, h*w, n)\n",
    "        cls_logits = cls_logits.permute(0, 2, 3, 1)  # [batch_size,h,w,class_num]\n",
    "        coords = coords_fmap2orig(cls_logits, stride).to(device=gt_boxes.device)  # [h*w,2]\n",
    "\n",
    "        cls_logits = cls_logits.reshape((batch_size, -1, class_num))  # [batch_size,h*w,class_num]\n",
    "        # 4 reshape cnt\n",
    "        cnt_logits = cnt_logits.permute(0, 2, 3, 1)   \n",
    "        cnt_logits = cnt_logits.reshape((batch_size, -1, 1))    # [batch_size,h*w,1]\n",
    "        # 5 reshape reg\n",
    "        reg_preds = reg_preds.permute(0, 2, 3, 1)\n",
    "        reg_preds = reg_preds.reshape((batch_size, -1, 4))  #  # [batch_size,h*w,4]\n",
    "\n",
    "        h_mul_w = cls_logits.shape[1]  # h*w\n",
    "\n",
    "        x = coords[:, 0]\n",
    "        y = coords[:, 1]\n",
    "        # 6 判断gt_box 包含了特征图上哪些grid(格点)\n",
    "        l_off = x[None, :, None] - gt_boxes[..., 0][:, None, :]  # [1,h*w,1]-[batch_size,1,m]-->[batch_size,h*w,m]\n",
    "        t_off = y[None, :, None] - gt_boxes[..., 1][:, None, :]\n",
    "        \n",
    "        r_off = gt_boxes[..., 2][:, None, :] - x[None, :, None]\n",
    "        b_off = gt_boxes[..., 3][:, None, :] - y[None, :, None]\n",
    "        \n",
    "        ltrb_off = torch.stack([l_off, t_off, r_off, b_off], dim=-1)  # [batch_size,h*w,m,4]\n",
    "\n",
    "        areas = (ltrb_off[..., 0] + ltrb_off[..., 2]) * (ltrb_off[..., 1] + ltrb_off[..., 3])  # [batch_size,h*w,m]\n",
    "\n",
    "        \n",
    "        off_min = torch.min(ltrb_off, dim=-1)[0]  # [batch_size,h*w,m]\n",
    "        off_max = torch.max(ltrb_off, dim=-1)[0]  # [batch_size,h*w,m]\n",
    "\n",
    "        mask_in_gtboxes = off_min > 0  # feature map 上的gird 是不是在框里\n",
    "        mask_in_level = (off_max > limit_range[0]) & (off_max <= limit_range[1])  # 这个框是不是在这一层里\n",
    "        # 7 找到离gt box 不远（1*stride）的grid\n",
    "        radiu = stride * sample_radiu_ratio\n",
    "        gt_center_x = (gt_boxes[..., 0] + gt_boxes[..., 2]) / 2\n",
    "        gt_center_y = (gt_boxes[..., 1] + gt_boxes[..., 3]) / 2\n",
    "        \n",
    "        c_l_off = x[None, :, None] - gt_center_x[:, None, :]  # [1,h*w,1]-[batch_size,1,m]-->[batch_size,h*w,m]\n",
    "        c_t_off = y[None, :, None] - gt_center_y[:, None, :]\n",
    "        c_r_off = gt_center_x[:, None, :] - x[None, :, None]\n",
    "        c_b_off = gt_center_y[:, None, :] - y[None, :, None]\n",
    "        \n",
    "        c_ltrb_off = torch.stack([c_l_off, c_t_off, c_r_off, c_b_off], dim=-1)  # [batch_size,h*w,m,4]\n",
    "        c_off_max = torch.max(c_ltrb_off, dim=-1)[0]\n",
    "        mask_center = c_off_max < radiu\n",
    "        # 选择 满足条件的grid\n",
    "        mask_pos = mask_in_gtboxes & mask_in_level & mask_center  # [batch_size,h*w,m]\n",
    "\n",
    "        areas[~mask_pos] = 99999999\n",
    "        areas_min_ind = torch.min(areas, dim=-1)[1]  # [batch_size,h*w]\n",
    "        reg_targets = ltrb_off[torch.zeros_like(areas, dtype=torch.uint8).scatter_(-1, areas_min_ind.unsqueeze(dim=-1),\n",
    "                                                                                   1)]  # [batch_size*h*w,4]\n",
    "        reg_targets = torch.reshape(reg_targets, (batch_size, -1, 4))  # [batch_size,h*w,4]\n",
    "\n",
    "        classes = torch.broadcast_tensors(classes[:, None, :], areas.long())[0]  # [batch_size,h*w,m]\n",
    "        cls_targets = classes[\n",
    "            torch.zeros_like(areas, dtype=torch.uint8).scatter_(-1, areas_min_ind.unsqueeze(dim=-1), 1)\n",
    "        ]\n",
    "        cls_targets = torch.reshape(cls_targets, (batch_size, -1, 1))  # [batch_size,h*w,1]\n",
    "\n",
    "        left_right_min = torch.min(reg_targets[..., 0], reg_targets[..., 2])  # [batch_size,h*w]\n",
    "        left_right_max = torch.max(reg_targets[..., 0], reg_targets[..., 2])\n",
    "        top_bottom_min = torch.min(reg_targets[..., 1], reg_targets[..., 3])\n",
    "        top_bottom_max = torch.max(reg_targets[..., 1], reg_targets[..., 3])\n",
    "        cnt_targets = ((left_right_min * top_bottom_min) / (left_right_max * top_bottom_max + 1e-10)).sqrt().unsqueeze(\n",
    "            dim=-1)  # [batch_size,h*w,1]\n",
    "\n",
    "        assert reg_targets.shape == (batch_size, h_mul_w, 4)\n",
    "        assert cls_targets.shape == (batch_size, h_mul_w, 1)\n",
    "        assert cnt_targets.shape == (batch_size, h_mul_w, 1)\n",
    "\n",
    "        # process neg coords\n",
    "        mask_pos_2 = mask_pos.long().sum(dim=-1)  # [batch_size,h*w]\n",
    "        # num_pos=mask_pos_2.sum(dim=-1)\n",
    "        # assert num_pos.shape==(batch_size,)\n",
    "        mask_pos_2 = mask_pos_2 >= 1  # 再确认一下\n",
    "        assert mask_pos_2.shape == (batch_size, h_mul_w)\n",
    "        cls_targets[~mask_pos_2] = 0   # [batch_size,h*w,1]\n",
    "        cnt_targets[~mask_pos_2] = -1  \n",
    "        reg_targets[~mask_pos_2] = -1\n",
    "\n",
    "        return cls_targets, cnt_targets, reg_targets"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "0014f77c19d8ed39e25776255b3127ff23c23b9b8eace650a1f6826ac7722592"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
